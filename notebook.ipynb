{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, decomposition, cross_validation, neighbors\n",
    "from sklearn.learning_curve import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sqlalchemy import create_engine\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up default parameters for making nice plots\n",
    "params = {\n",
    "    'axes.color_cycle': ['5DA5DA', 'FAA43A', '60BD68', 'F17CB0', 'B2912F', 'B276B2', 'DECF3F', 'F15854', '4D4D4D'],\n",
    "    'axes.labelsize': 14,\n",
    "    'font.size': 14,\n",
    "    'legend.fontsize': 14,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14,\n",
    "    'axes.linewidth': 2,\n",
    "    'xtick.major.width': 2,\n",
    "    'ytick.major.width': 2,\n",
    "    'lines.linewidth': 2,\n",
    "    'lines.marker': 'o'\n",
    "   }\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "engine = create_engine('mysql://root:pass@localhost/moviedb?charset=utf8', encoding = 'utf-8')\n",
    "df1 = pd.read_sql_table('themoviedb', engine)\n",
    "df2 = pd.read_sql_table('omdb', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(df1.loc[0:1,:])\n",
    "df2.loc[0:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make genres the columns of a new data frame, with binary entries\n",
    "s1 = df1['genres']\n",
    "s2 = df2['Genre']\n",
    "movies = df2['Title']\n",
    "dfgenre = pd.DataFrame()\n",
    "for ind in s1.index:\n",
    "    # filter out empty strings, and merge genre information from the two databases\n",
    "    temp = np.array(filter(None, s1[ind].split(', ') + s2[ind].split(', ')), dtype = object)\n",
    "    temp[temp == 'Sci-Fi'] = 'Science Fiction'\n",
    "    temp = set(temp)\n",
    "    s = pd.Series([1]*len(temp), index = temp, name = ind)\n",
    "    dfgenre = dfgenre.append(s)\n",
    "dfgenre = dfgenre.fillna(0)\n",
    "genres = dfgenre.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take a look at genre compositions\n",
    "np.sum(dfgenre).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rid of foreign, short, and documentary, since there are only a few data points for those\n",
    "# remove rows first, then columns\n",
    "ind1 = np.logical_not(dfgenre[['Foreign', 'Short', 'Documentary']].apply(any, axis = 1))\n",
    "col1 = np.logical_not(np.in1d(dfgenre.columns, ['Foreign', 'Short', 'Documentary']))\n",
    "\n",
    "# focus on rotten tomatoes for now (it's the most well known, even if it's not the best metric)\n",
    "# throw out the ones that have no rotten or no fresh (to avoid issue with logistic function)\n",
    "ind2 = np.logical_not(np.in1d(df2['tomatoFresh'], ['N/A', '0'])) & np.logical_not(np.in1d(df2['tomatoRotten'], ['N/A', '0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put together data to use with linear regression model\n",
    "X = dfgenre.loc[ind1 & ind2, col1]\n",
    "fresh = df2['tomatoFresh'][ind1 & ind2].map(float)\n",
    "rotten = df2['tomatoRotten'][ind1 & ind2].map(float)\n",
    "y = fresh / (fresh + rotten)   # calculate tomatometer to more than just 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize row vectors to be the same length in genre-space\n",
    "numgenres = np.sum(X, axis = 1)\n",
    "X = X.apply(lambda x: x/np.sqrt(numgenres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an inverse logistic function to transform output to go from (0,1) to (-inf,+inf)\n",
    "def fun(y): return np.log(y/(1-y))\n",
    "def ifun(yprime): return 1/(1+np.exp(-yprime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot histograms of the output data before and after transformation\n",
    "plt.hist(y)\n",
    "plt.xlabel('Tomatometer Score')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(fun(y))\n",
    "plt.xlabel('Logistically Mapped Tomatometer Score')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit a linear regression model, using cross-validation to pick regularization parameter\n",
    "k = 10\n",
    "kf = cross_validation.KFold(y.size, k, shuffle = True)\n",
    "reg = linear_model.RidgeCV(alphas = (0, 0.03, 0.1, 0.3, 1, 3, 10), cv = kf).fit(X,fun(y))\n",
    "reg.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit a new model using the correct alpha\n",
    "reg = linear_model.Ridge(alpha = 3).fit(X,fun(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at coefficients and intercept\n",
    "print reg.intercept_\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the R-square (should be greater than zero)\n",
    "reg.score(X,fun(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a table of the relevant results\n",
    "# calculate average movie score for each genre\n",
    "means = []\n",
    "for name in genres[col1]:\n",
    "    ind = X[name] != 0\n",
    "    means.append(y[ind].mean())\n",
    "means = np.array(means)\n",
    "\n",
    "dfprint = pd.DataFrame()\n",
    "dfprint['Genres'] = genres[col1]\n",
    "dfprint['Weights'] = reg.coef_\n",
    "dfprint['Pure Genre Score'] = ifun(reg.coef_ + reg.intercept_)\n",
    "dfprint['Average Movie Score'] = means\n",
    "dfprint = dfprint.set_index('Genres')\n",
    "dfprint['Number of Movies'] = dfgenre.loc[ind1 & ind2, col1].sum()\n",
    "dfprint = dfprint.sort_values('Weights', ascending = False)\n",
    "dfprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute learning curves using K-fold cross-validation\n",
    "size, train, test = learning_curve(reg, X, fun(y), train_sizes = np.arange(0.05, 1, 0.05), cv = kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the learning curves\n",
    "plt.plot(size, train.mean(1), label = 'Training Set')\n",
    "plt.plot(size, test.mean(1), label = 'CV Set')\n",
    "legend = plt.legend(loc = 4)\n",
    "legend.get_frame().set_linewidth(2)\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Average R-square')\n",
    "plt.title('Learning Curves with K-fold CV = %d' % k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the predicted movie scores versus the actual movie scores\n",
    "ypred = ifun(reg.predict(X))\n",
    "plt.scatter(y, ypred)\n",
    "plt.xlabel('Actual Tomatometer Score')\n",
    "plt.ylabel('Predicted Tomatometer Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# just the genre data is interesting, try unsupervised learning\n",
    "# fit a PCA model\n",
    "pca = decomposition.PCA().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take a look at the means and components for one of the eigenvectors\n",
    "print pca.mean_\n",
    "pca.components_[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform data into PCA-space\n",
    "Xpca = pca.transform(X)\n",
    "\n",
    "# compute eigenvalues (just the std, pca model doesn't return this for some reason)\n",
    "eigval = np.std(Xpca, axis = 0)\n",
    "\n",
    "# inverse transform to find what \"movie\" an eigenvector would represent\n",
    "vec = pca.inverse_transform(np.diag(eigval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do a k-nearest-neighbor search to find the movies near the eigenvectors (i.e. the best examples of each meta-genre)\n",
    "num = 10\n",
    "knn = neighbors.NearestNeighbors(n_neighbors = num).fit(X)\n",
    "dist, indknn = knn.kneighbors(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out some useful results from the pca\n",
    "dftemp = dfgenre.loc[ind1 & ind2, col1]\n",
    "for row in range(20):\n",
    "    # list eigenvectors in decreasing order of explained variance\n",
    "    print 'Percent variance explained = %g' % pca.explained_variance_ratio_[row]\n",
    "    \n",
    "    # print a table listing the eigenvector components next to their corresponding genre\n",
    "    ind = vec[row,:].argsort()[::-1]\n",
    "    dfprint = pd.DataFrame(columns = genres[col1][ind])\n",
    "    dfprint = dfprint.append(pd.Series(vec[row,ind], index = genres[col1][ind], name = 'Components'))\n",
    "    display(dfprint)\n",
    "    \n",
    "    # print the titles of the nearest movies, along with their genres\n",
    "    mov = movies[ind1 & ind2].values[indknn[row,:]]\n",
    "    print 'Example movies:'\n",
    "    for tempind in range(num):\n",
    "        gen = ', '.join(dftemp.columns[dftemp.values[indknn[row,tempind]] == 1])\n",
    "        print '%-40s (%s)' % (mov[tempind], gen)\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
